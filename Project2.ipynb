{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c2a1b21f-fbd3-4ee6-8146-a0fb3fbb08e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#MAT345 Project 2\n",
    "#Fall 2023\n",
    "#Jasmine Widgery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "df0995fe-9219-4595-b683-3fd1956621e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Imports\n",
    "import os\n",
    "import re #regex\n",
    "import shutil\n",
    "from collections import defaultdict\n",
    "import operator\n",
    "import numpy\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5f90410c-3d5b-4d09-84df-5c9c1a91522f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Separate data into testing and training categories\n",
    "train_eh = \"Training/easy_ham/\"\n",
    "train_hh = \"Training/hard_ham/\"\n",
    "train_spam = \"Training/spam/\"\n",
    "\n",
    "test_eh = \"Testing/easy_ham/\"\n",
    "test_hh = \"Testing/hard_ham/\"\n",
    "test_spam = \"Testing/spam/\"\n",
    "\n",
    "trainingFolders = [train_eh, train_hh, train_spam]\n",
    "testingFolders = [test_eh, test_hh, test_spam]\n",
    "\n",
    "for index in range(0, len(trainingFolders)):\n",
    "    for file in os.listdir(trainingFolders[index]):\n",
    "        #if message number is divisible by 4\n",
    "        name = re.search(\".+?(?=\\.)\", file).group()\n",
    "        nameAsInt = int(name)\n",
    "        #commented out because I only needed to do this once\n",
    "        #if nameAsInt % 4 == 0:\n",
    "            #print(\"From: \" + trainingFolders[index] + file)\n",
    "            #print(\"To: \" + testingFolders[index] + file)\n",
    "            #shutil.move(trainingFolders[index] + file, testingFolders[index] + file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f8770999-7b1f-4d26-80b3-b732d3a8ce3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loop through every file in every folder to create list of words that compose subject lines.\n",
    "\n",
    "#precompute num spam and ham messages\n",
    "numSpam = 0\n",
    "numHam = 0\n",
    "\n",
    "#create key value pairs where key is word and value is frequency in spam or ham messages, respectively\n",
    "hamDict = defaultdict(int)\n",
    "spamDict = defaultdict(int)\n",
    "\n",
    "#all words\n",
    "allWords = []\n",
    "#remove common words (conjunctions, articles, prepositions)\n",
    "common = [\"THE\", \"AT\", \"AND\", \"IF\", \"BUT\", \"AS\", \"TO\", \"OR\", \"ON\", \"SO\", \"FOR\", \"NOR\", \"YET\", \"WITH\", \"YOU\", \"YOUR\", \"OF\", \"IN\", \"GET\", \"IS\", \"FROM\", \"WHILE\", \"WE\"]\n",
    "\n",
    "for index in range(0, len(trainingFolders)):\n",
    "    for file in os.listdir(trainingFolders[index]):\n",
    "        if(trainingFolders[index] == train_spam):\n",
    "            numSpam += 1\n",
    "        else:\n",
    "            numHam += 1\n",
    "        f = open(trainingFolders[index] + file, encoding = \"utf8\", errors=\"ignore\")\n",
    "        message = f.read()\n",
    "        matchObj = re.search(\"(?<=Subject:).*?(?=\\n)\", message)\n",
    "        if matchObj != None:\n",
    "            subject = matchObj.group()\n",
    "        words = subject.split()\n",
    "        for word in words:\n",
    "            word = word.upper() #remove casing\n",
    "            if word.isalpha(): #add only words that are strictly letters\n",
    "                if word not in common:\n",
    "                    if len(word) > 1: #don't add single characters\n",
    "                        if(trainingFolders[index] == train_spam):\n",
    "                            spamDict[word] += 1\n",
    "                        elif(trainingFolders[index] == train_eh or train_hh):\n",
    "                            hamDict[word] += 1\n",
    "                        allWords.append(word) #don't add common words\n",
    "\n",
    "#remove duplicates\n",
    "allWords = list(set(allWords))\n",
    "\n",
    "\n",
    "#At this point, we have:\n",
    "# - allWords - list of all words to test against\n",
    "# - numSpam = num spam msgs\n",
    "# - numHam = num ham msgs\n",
    "# - hamDict[word] = num occurences of word in ham\n",
    "# - spamDict[word] = num occurences of word in spam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ed091b30-b5f3-4c34-a338-a891aa11e3ec",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 spammiest: highest P(spam | word): \n",
      "('RATES', 0.9282811621280109) with frequency: 12\n",
      "('PER', 0.8996061800068765) with frequency: 8\n",
      "('MORTGAGE', 0.8996061800068765) with frequency: 8\n",
      "('MONEY', 0.8996061800068765) with frequency: 8\n",
      "('SYSTEMWORKS', 0.8996061800068765) with frequency: 8\n",
      " \n",
      "5 hammiest: highest P(ham | word): \n",
      "('BROADBAND', 0.5) with frequency: 1\n",
      "('HUBRIS', 0.5) with frequency: 1\n",
      "('OPTICAL', 0.5) with frequency: 4\n",
      "('LIBERAL', 0.5) with frequency: 8\n",
      "('BRINGS', 0.5) with frequency: 1\n"
     ]
    }
   ],
   "source": [
    "#for each word, compute probabilities for P(word | ham) and P (word | spam)\n",
    "\n",
    "#print(str(numSpam))\n",
    "#print(str(numHam))\n",
    "alpha = 1\n",
    "beta = 2\n",
    "\n",
    "numTotalMsgs = numHam + numSpam\n",
    "totalProbSpam = (numSpam) / (numTotalMsgs) #probability a message is spam\n",
    "totalProbHam = 1 - totalProbSpam\n",
    "\n",
    "\n",
    "probSpamDict = defaultdict(float)\n",
    "probHamDict = defaultdict(float)\n",
    "\n",
    "#spamDict[word] is frequency of word in spam messages\n",
    "#hamDict[word] is frequency of word in ham messages\n",
    "#HW Step 3 Part B\n",
    "for word in allWords:\n",
    "    probWordGivenSpam = ((alpha + spamDict[word]) / (beta + numSpam)) #P(word | spam)\n",
    "    probWordGivenHam = ((alpha + hamDict[word]) / (beta + numHam)) #P(word | ham)\n",
    "    probSpamDict[word] = probWordGivenSpam\n",
    "    probHamDict[word] = probWordGivenHam\n",
    "    \n",
    "dictSpamGivenWords = defaultdict(float)\n",
    "dictHamGivenWords = defaultdict(float)\n",
    "\n",
    "    \n",
    "sorted_probSpamDict = sorted(probSpamDict.items(), key=operator.itemgetter(1),reverse=True)\n",
    "sorted_probHamDict = sorted(probHamDict.items(), key=operator.itemgetter(1),reverse=True)\n",
    "\n",
    "\n",
    "#get spammiest/hammiest words\n",
    "for word in allWords: \n",
    "    dictSpamGivenWords[word] = (probSpamDict[word] * totalProbSpam) / ((probSpamDict[word] * totalProbSpam) + (probHamDict[word] * totalProbHam))\n",
    "    dictHamGivenWords[word] = (probHamDict[word] * totalProbHam) / ((probHamDict[word] * totalProbHam) + (probHamDict[word] * totalProbHam))\n",
    "    \n",
    "#convert dictionaries to list to output top 5\n",
    "sorted_SpamGivenWords = sorted(dictSpamGivenWords.items(), key=operator.itemgetter(1),reverse=True)\n",
    "sorted_HamGivenWords = sorted(dictHamGivenWords.items(), key=operator.itemgetter(1),reverse=True)\n",
    "\n",
    "\n",
    "\n",
    "print(\"5 spammiest: highest P(spam | word): \")\n",
    "for index in range(0, 5):\n",
    "    print(str(sorted_SpamGivenWords[index]) + \" with frequency: \" + str(spamDict[sorted_SpamGivenWords[index][0]]))\n",
    "\n",
    "print(\" \")\n",
    "print(\"5 hammiest: highest P(ham | word): \" )\n",
    "for index in range(0, 5):\n",
    "    print(str(sorted_HamGivenWords[index]) + \" with frequency: \" + str(hamDict[sorted_HamGivenWords[index][0]]))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "39c0678a-d9ad-4c00-9566-c7818353da77",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spam predict spam: 31\n",
      "spam predict ham: 95\n",
      "ham predict ham: 699\n",
      "ham predict spam: 0\n",
      "Accuracy: 0.88484848484848488414656\n",
      "Precision: 1.00000000000000000000000\n",
      "Recall: 0.24603174603174601808853\n"
     ]
    }
   ],
   "source": [
    "#Naive Bayes implementation (compact)\n",
    "\n",
    "y = []\n",
    "z = []\n",
    "y0 = 0.0\n",
    "z0 = 0.0\n",
    "for word in allWords:\n",
    "    #print(\"Prob of \" + word + \" being spam is \" + str(probSpamDict[word]))\n",
    "    y.append(numpy.log(probSpamDict[word] / (1 - probSpamDict[word])))\n",
    "    y0 += numpy.log(1 - probSpamDict[word])\n",
    "    #print(\"Prob of \" + word + \" being ham is \" + str(probHamDict[word]))\n",
    "    z.append(numpy.log(probHamDict[word] / (1 - probHamDict[word])))\n",
    "    z0 += numpy.log(1 - probHamDict[word])  \n",
    "    \n",
    "\n",
    "def naiveBayes(subjectWords, totalProbSpam_t, totalProbHam_t):\n",
    "    a = []\n",
    "    for word in allWords:\n",
    "        if word in subjectWords:\n",
    "            a.append(1)\n",
    "        else:\n",
    "            a.append(0)\n",
    "    numerator = ((math.exp(numpy.dot(a, y) + y0)) * totalProbSpam_t)\n",
    "    denominator = numerator + ((math.exp(numpy.dot(a, z) + z0)) * totalProbHam_t)\n",
    "    probMsgSpam = numerator / denominator\n",
    "    if probMsgSpam > 0.55:\n",
    "        #print(\"Given words: \" + str(subjectWords))\n",
    "        #print(\"Probability spam: \" + str(probMsgSpam) + \" message predicted to be spam.\")\n",
    "        return True\n",
    "    else:\n",
    "        #print(\"Probability ham: \" + str(1 - probMsgSpam) + \" message predicted to be ham.\")\n",
    "        return False\n",
    "\n",
    "\n",
    "      \n",
    "correctSpam = 0 #predicted spam, it's spam\n",
    "incorrectSpam = 0 #predicted ham, it's spam\n",
    "correctHam = 0 #predicted ham, it's ham\n",
    "incorrectHam = 0 #predicted spam, is ham\n",
    "for index in range(0, len(testingFolders)):\n",
    "    for fileIndex, file in enumerate(os.listdir(testingFolders[index])):\n",
    "        subjectWords = []\n",
    "        f = open(testingFolders[index] + file, encoding = \"utf8\", errors=\"ignore\")\n",
    "        message = f.read()\n",
    "        matchObj = re.search(\"(?<=Subject:).*?(?=\\n)\", message)\n",
    "        if matchObj != None:\n",
    "            subject = matchObj.group()\n",
    "        words = subject.split()\n",
    "        for word in words:\n",
    "            word = word.upper()\n",
    "            if word.isalpha(): #add only words that are strictly letters\n",
    "                if word not in common:\n",
    "                    if len(word) > 1: #don't add single characters\n",
    "                        subjectWords.append(word) #don't add common words\n",
    "                        subjectWords = list(set(subjectWords)) #remove duplicates\n",
    "        isSpam = naiveBayes(subjectWords, totalProbSpam, totalProbHam)\n",
    "        if(testingFolders[index] == test_spam):\n",
    "            if(isSpam):\n",
    "                correctSpam += 1\n",
    "            elif(not isSpam):\n",
    "                incorrectSpam += 1\n",
    "        elif((testingFolders[index] == test_eh) or (testingFolders[index] == test_hh)):\n",
    "            if(isSpam):\n",
    "                incorrectHam += 1\n",
    "            elif(not isSpam):\n",
    "                correctHam += 1\n",
    "        \n",
    "\n",
    "accuracy = (correctSpam + correctHam) / (correctSpam + correctHam + incorrectSpam + incorrectHam)\n",
    "precision = correctSpam / (correctSpam + incorrectHam)\n",
    "recall = correctSpam / (correctSpam + incorrectSpam)\n",
    "\n",
    "accuracyStr = '{:.23f}'.format(accuracy)\n",
    "precisionStr = '{:.23f}'.format(precision)\n",
    "recallStr = '{:.23f}'.format(recall)\n",
    "\n",
    "print(\"spam predict spam: \" + str(correctSpam))\n",
    "print(\"spam predict ham: \" + str(incorrectSpam))\n",
    "print(\"ham predict ham: \" + str(correctHam))\n",
    "print(\"ham predict spam: \" + str(incorrectHam))\n",
    "\n",
    "print(\"Accuracy: \" + accuracyStr)\n",
    "print(\"Precision: \" + precisionStr)\n",
    "print(\"Recall: \" + recallStr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
